## Explainable Computer Vision with embeddings and KNN classifier.

*Authors: Olaf Werner, Bogdan JastrzÄ™bski (Warsaw University of Technology)*

### Abstract


### Introduction
Computer vision is widely known use case for neural networks. However neural networks are infamous for their complexity and lack of interpretability. On the other hand simple classifiers like KNN have really poor results for complex tasks like image recognition. In this article we will prove that it is possible to get best of both worlds using emmbeddings. 

### Data
We are going to use dataset [Fashion-Mnist](https://www.openml.org/d/40996). Fashion-MNIST is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Classes are following: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot.

### Methodology

The simplest and one of the most robust classifiers is KNN. It doesn't generalize information, instead it saves training dataset and during prediction it finds the most similar historical observations and predicts label of a new observation based on their labels.

However, it not only doesn't have the capacity to distinguish important features from not important ones, but also to find more complex interactions between variables. 

One way to improve KNN's performance is to preced closest neighbour computation with transformation of the space of observations, so that the derivative variables are more meaningful. Such beneficial transformation is called embedding. It can be done in various ways. 

The question is, whether or not the new classifier is interpretable. We argue, that it is. The main reason is that even if we can't interpret the embedding part, we can at least provide historical data that our model used to make prediction. Someone could argue, that it can be done with every classifier, just by finding training data that obtains the most similar prediction. However, with our classifier we can say for sure, that prediction were purely made based on the most similar cases in our dataset, which is fundamentally not true about different classifiers.

An embedding can be done made in various ways. In this article we will explore different embedding techniques, including:

* SVD embedding

* Logistic Regression Autoencoder

* Self Organizing Maps

* Convolutional Autoencoder

### Black-Box Convolutional Neural Networks

Classical approach in computer vision is to use convolutional neural networks. A standard artificial neural network sees all variables as being independent from each other. It doesn't capture the same patterns across image space, nor it recognises, that two pixels next to each other are somehow related. Shifted image is something completly different to a standard neural network from it's original. Therefore, training a standard neural network is tricky, it requires very big dataset and takes a lot of time. There is, however, a smarter approach that has a capacity to cope with those problems. Namely, convolutional neural networks. 

A convolutional neural network is an artificial neural network, that tries to capture spacial dependencies between variables, for instance dimensions of pixels that are close to each other.
It does that via introducing convolution. The easiest interpretation of convolutional neural network is that instead of training training big network that uses all variables (in our case all pixels), we train smaller transformation with smaller number of variables (smaller subset of pixels close to each other), that we use in many different places on the image. In some sense we train filters. Every filter produces a corresponding so called "channel". After first layer we can continue filtering channels using convolutional layers. We place a danse layer (or a number of them) at the end and it's result is our prediction. For further reading, please see ... .

Having a very good performance, they are impossible to explain. There are some techniques of visualising filters, however more complex networks are generally uninterpretable. Along with standard artificial neural network, we will use it as an instance of robust classifier for comparing results. 

#### Architecure and Implementation

Our implementation of convolutional neural networks consist of the following layers:

- Conv2d(1, a, 5)
- Conv2d(a, a, 5)
- Conv2d(a, b, 5)
- Linear(500, 200)
- Linear(200, 10)



### Results


### Conclusions
